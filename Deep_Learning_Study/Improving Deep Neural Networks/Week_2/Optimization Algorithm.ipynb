{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batch\n",
    "\n",
    "### Batch Gradient Descent:\n",
    "- **Usage:** Trains the model using the **entire training dataset** for each iteration.\n",
    "\n",
    "### Mini-Batch Gradient Descent:\n",
    "- **Usage:** Splits the entire dataset into **smaller sets** called mini-batches for each iteration.\n",
    "\n",
    "### Stochastic Gradient Descent (SGD):\n",
    "- **Usage:** A special case of mini-batch with **size 1**.\n",
    "\n",
    "### Summary: \n",
    "#### Advantages:\n",
    "- Results in **faster computation times**, particularly beneficial for large datasets.\n",
    "\n",
    "#### Disadvantages:\n",
    "- Can lead to reduced accuracy in parameter convergence towards the **data centroid**.\n",
    "\n",
    "- Larger mini-batches may cause **longer training times** compared to using the full dataset.\n",
    "\n",
    "![Image](./image/MiniBatch.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially Weighted Averages\n",
    "\n",
    "\n",
    "### Definition:\n",
    "- **Usage**: Speed up the Gradient Descent if it optimize with the same direction\n",
    "\n",
    "- A **statistical method** for calculating the running average of data.\n",
    "\n",
    "### Formula:\n",
    "- Initial value: $v_0 = 0$\n",
    "- Update rule: $v_t = βv_{t-1} + (1 - β)θ_t$\n",
    "\n",
    "### Illustration:\n",
    "- Graph displays **daily temperature** readings.\n",
    "- Average computed with $β = 0.9$.\n",
    "- Implies an average over approximately $\\frac{1}{1-β} = 10$ days.\n",
    "\n",
    "### Limitation:\n",
    "- Early estimates can be biased, particularly with $v_0 = 0$ initialization (indicated by the purple curve on the graph).\n",
    "\n",
    "### Bias Correction Solution:\n",
    "- Correct the bias with the formula: $v_t = \\frac{v_t}{1 - β^{t}}$\n",
    "\n",
    "![Image](./image/EWA.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent With Momentum\n",
    "### Basic Explanation:\n",
    "- **Momentum** is analogous to movement. Rather than updating parameters in isolation each epoch, it incorporates the 'velocity' of changes from previous epochs to accelerate learning.\n",
    "\n",
    "### Update Formula:\n",
    "- For the $l$-th layer, with $L$ being the number of layers, $β$ as the momentum, and $α$ as the learning rate:\n",
    "    $v_{dW^{[l]}} = βv_{dW^{[l]}} + (1 - β)dW^{[l]}$<br>\n",
    "    $W^{[l]} = W^{[l]} - αv_{dW^{[l]}}$<br>\n",
    "    \n",
    "    $v_{db^{[l]}} = βv_{db^{[l]}} + (1 - β)db^{[l]}$<br>\n",
    "    $b^{[l]} = b^{[l]} - αv_{db^{[l]}}$<br>\n",
    "  \n",
    "### Physical Interpretation:\n",
    "- $v_{dw}$: velocity (velocity)\n",
    "- $dW$: acceleration (acceleration)\n",
    "- $Beta$: limits the acceleration process (friction)\n",
    "\n",
    "### Note:\n",
    "- Some literature suggests omitting $(1 - beta)$, potentially modifying the learning rate $alpha$ to ensure the essence of Exponentially weighted averages is maintained.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMS Prop\n",
    "\n",
    "- **Usage**: Change direction of Gradient Descent\n",
    "\n",
    "- **Definition**: When observing contour plots for optimization cases as shown, there can be large discrepancies in the gradients of db and dW.\n",
    "\n",
    "### Mitigation Measures for Discrepancies:\n",
    "- Update velocities for weights (W) and biases (b) using the formulas:\n",
    "\n",
    "    $s_{dw} = β * s_{dw} + (1 - β) * dW * dW$<br><br>\n",
    "    $s_{db} = β * s_{db} + (1 - β) * db * db$\n",
    "\n",
    "- Update parameters (add $\\epsilon$ to ensure we do not divide for zero ):\n",
    "\n",
    "    $W = W - α * \\frac{dW}{\\sqrt{s_{dw}} + ε}$<br><br>\n",
    "    $b = b - α * \\frac{db}{\\sqrt{s_{db}} + ε}$\n",
    "\n",
    "### Basic Explanation:\n",
    "- Large derivatives are scaled down by their squared values, thus reducing the discrepancy between the gradients of different parameters.\n",
    "\n",
    "- This guides the optimization more steadily towards the data center.\n",
    "\n",
    "- As a result of this method, one can increase the learning rate without worrying about divergence.\n",
    "\n",
    "### Visual Illustration:\n",
    "- The contour plots demonstrate the path of optimization with and without RMSprop.\n",
    "\n",
    "- With gradient descent, the path is more erratic and oscillatory.\n",
    "\n",
    "- RMSprop provides a smoother trajectory towards the minimum.\n",
    "\n",
    "![Image](./image/RMS.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam optimization algorithm\n",
    "\n",
    "- Stands for Adaptive Moment Estimation.\n",
    "\n",
    "- Adam optimization and RMSprop are among the optimization algorithms that worked very well with a lot of NN architectures.\n",
    "\n",
    "- Adam optimization simply puts RMSprop and momentum together $\\implies$ It's also speed up and optimize the direction of algorithm\n",
    "\n",
    "### Pseudo Code\n",
    "\n",
    "$v_{dW} = 0, v_{db} = 0$<br>\n",
    "$s_{dW} = 0, s_{db} = 0$<br>\n",
    "- On iteration $t$:<br>\n",
    "  - compute $dw, db$ on current mini-batch<br>             \n",
    "\t\t\t\n",
    "  - $v_{dW} = (beta_{1} * v_{dW}) + (1 - beta_{1}) * dW$     # momentum\n",
    "  - $v_{db} = (beta_{1} * v_{db}) + (1 - beta_{1}) * db$     # momentum\n",
    "\t\t\t\n",
    "  - $s_{dW} = (beta_{2} * s_{dW}) + (1 - beta_{2}) * dW^2$   # RMSprop\n",
    "  - $s_{db} = (beta_{2} * s_{db}) + (1 - beta_{2}) * db^2$   # RMSprop\n",
    "\t\t\t\n",
    "  - $v_{dW} = \\frac{v_{dW}}{1 - beta_{1}^{t}}$      # fixing bias\n",
    "  - $v_{db} = \\frac{v_{db}}{1 - beta_{1}^{t}}$      # fixing bias\n",
    "\t\t\t\n",
    "  - $s_{dW} = \\frac{s_{dW}}{1 - beta_{2}^{t}}$      # fixing bias\n",
    "  - $s_{db} = \\frac{s_{db}}{1 - beta_{2}^{t}}$      # fixing bias\n",
    "\t\t\t\t\t\n",
    "  - $W = W - \\alpha * \\frac{v_{dW}}{sqrt(s_{dW}) + \\epsilon}$\n",
    "  - $b = B - \\alpha * \\frac{v_{db}}{sqrt(s_{db}) + \\epsilon}$\n",
    "\n",
    "\n",
    "\n",
    "- Hyperparameters for Adam:\n",
    "    - $\\alpha$: needed to be tuned.\n",
    "    - $beta_{1}$: parameter of the momentum - 0.9 is recommended by default.\n",
    "    - $beta_{2}$: parameter of the RMSprop - 0.999 is recommended by default.\n",
    "    - $\\epsilon$: 10^-8 is recommended by default."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Decay\n",
    "\n",
    "### Issue:\n",
    "- A large initial $\\alpha$ (learning_rate) can accelerate learning but risks overshooting the minimum accuracy point.\n",
    "- Reducing $alpha$ over time is necessary for precise convergence.\n",
    "\n",
    "### Solution:\n",
    "- Update the learning rate $alpha$ over time based on the training stage.\n",
    "- **Per Epoch:**\n",
    "  - $\\alpha = \\frac{1}{1 + \\text{decayRate} \\times \\text{epochNumber}} \\times \\alpha_0$\n",
    "- **Per Epoch Interval:**\n",
    "  - $\\alpha = \\frac{1}{1 + \\text{decayRate} \\times \\frac{\\text{epochNum}}{\\text{timeInterval}}} \\times \\alpha_0$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem of local optima\n",
    "\n",
    "- It's unlikely to get stuck in a bad local optima in high dimensions, it is much more likely to get to the saddle point rather to the local optima in the high dimension-dataset.\n",
    "\n",
    "- **Plateaus** can make learning slow:\n",
    "    - Plateau is a region where the derivative is close to zero for a long time.\n",
    "    - This is where algorithms like momentum, RMSprop or Adam can help."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
