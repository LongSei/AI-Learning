{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Overfitting Problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Collect More Training Data**\n",
    "\n",
    "   - **Definition**: More data can help the model generalize better, reducing overfitting. It allows the algorithm to learn a function that captures the underlying trend without being overly complex.\n",
    "\n",
    "![Image](./image/CollectData.png)\n",
    "\n",
    "2. **Feature Selection**\n",
    "\n",
    "   - **Definition**: Reducing the number of features can help prevent the model from becoming too complex. This involves selecting a subset of the most relevant features to use in the model.\n",
    "\n",
    "   - **Intuition-Based Selection**: Using domain knowledge to choose the most relevant features.\n",
    "\n",
    "   - **Automated Feature Selection**: Algorithms that automatically select the most relevant features. These methods will be discussed in more detail in Course 2.\n",
    "\n",
    "![Image](./image/FeatureSelecting.png)\n",
    "\n",
    "3. **Regularization**\n",
    "\n",
    "   - **Definition**: Regularization techniques adjust the complexity of the model by adding a penalty on the size of the coefficients for the features. This discourages the model from becoming too complex and fitting the training data too closely.\n",
    "\n",
    "   - **Effect on Parameters**: Encourages smaller parameter values, which can lead to a simpler model that generalizes better.\n",
    "\n",
    "![Image](./image/RegularizationData.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
